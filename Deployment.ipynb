{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Levenshtein\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "import gradio as gr\n",
    "from langdetect import detect\n",
    "from Bio.Align import PairwiseAligner\n",
    "from scipy.spatial import distance\n",
    "import jaro\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import codecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('classifier')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector mapping for Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_mapping = {\n",
    "                    1: [0,0,0],\n",
    "                    2: [0,2,0],\n",
    "                    3: [1,1,1],\n",
    "                    4: [2,1,0],\n",
    "                    5: [4,1,0],\n",
    "                    6: [5,1,0]\n",
    "                }\n",
    "\n",
    "def mapping(emotions):\n",
    "    vectors = []\n",
    "    for i in emotions:\n",
    "        vectors.append(vector_mapping[i])\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Detect the language of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language(scenes):\n",
    "    scene = scenes[0]\n",
    "    try:\n",
    "        lang = detect(scene)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the screenplay dataset and remove the french movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('screenplay datasets/scriptemotionjson.json')\n",
    "df['lang'] = df['scenes'].apply(language)\n",
    "df.drop(df[df['lang'] == 'fr'].index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df['3d_vectors'] = df['emotions'].apply(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the emotions to colors that represent them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "color_mapping = {\n",
    "    'joy': (248, 255, 149),       \n",
    "    'love': (255, 199, 234),     \n",
    "    'surprise': (166, 255, 150),  \n",
    "    'sadness':(12, 53, 106),    \n",
    "    'anger': (223, 46, 56),     \n",
    "    'fear': (53, 124, 60)\t\n",
    "}\n",
    "code_mapping = {\n",
    "    '6': (248, 255, 149),       \n",
    "    '5': (255, 199, 234),     \n",
    "    '4': (166, 255, 150),  \n",
    "    '3': (12, 53, 106),    \n",
    "    '2': (223, 46, 56),     \n",
    "    '1': (53, 124, 60)\t\n",
    "}\n",
    "emotion_mapping = {\n",
    "     'joy':6,\n",
    "     'love':5,\n",
    "     'surprise':4,\n",
    "     'sadness':3,\n",
    "     'anger':2,\n",
    "     'fear':1\n",
    "}\n",
    "classifier_labels = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string(e):\n",
    "    x = [str(i) for i in e]\n",
    "    string = ''.join(x)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert the vector into an image representing the emotional pattern in the film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_barcode(idx):\n",
    "    image = Image.new('RGB', (700,300), 'white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    length = 700//100\n",
    "    emotion_list = df['emotions'][idx]\n",
    "    for i in range(0,100):\n",
    "        code = emotion_list[i]\n",
    "        color = code_mapping[str(code)]\n",
    "        draw.rectangle([length*i,0,length*(i+1), 300], fill=color)\n",
    "    return image\n",
    "\n",
    "def emo_barcode_file(emotion_list):\n",
    "    image = Image.new('RGB', (700,300), 'white')    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "    length = 700//100\n",
    "    for i in range(0,100):\n",
    "        code = emotion_list[i]\n",
    "        color = code_mapping[str(code)]\n",
    "        draw.rectangle([length*i,0,length*(i+1), 300], fill=color)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to calculate similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['emotions'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = idx\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['emotions'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100,5):\n",
    "            score += distance.cosine(e1[i:i+5],e2[i:i+5])\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[1:6]\n",
    "\n",
    "def euclid(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['3d_vectors'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = mapping(idx)\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['3d_vectors'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100):\n",
    "            score += distance.euclidean(e1[i],e2[i])\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[1:6]\n",
    "\n",
    "def jaro_metric(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['emotions'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = idx\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['emotions'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100,5):\n",
    "            score += jaro.jaro_metric(string(e1[i:i+5]),string(e2[i:i+5]))\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[-6:-1]\n",
    "\n",
    "def hamming(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['emotions'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = idx\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['emotions'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100,5):\n",
    "            score += distance.hamming(e1[i:i+5],e2[i:i+5])\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[1:6]\n",
    "\n",
    "def needleman(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['emotions'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = idx\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['emotions'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100,5):\n",
    "            score += PairwiseAligner.align(PairwiseAligner,e1[i:i+5],e2[i:i+5])\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[1:6]\n",
    "\n",
    "def Leven(idx):\n",
    "    a_list = []\n",
    "    if type(idx) == int:\n",
    "        e1 = df['emotions'][idx]\n",
    "    if type(idx) == list:\n",
    "        e1 = idx\n",
    "    for i in range(0,df.shape[0]):\n",
    "        e2 = df['emotions'][i]\n",
    "        score = 0\n",
    "        for i in range(0,100,5):\n",
    "            score += Levenshtein.distance(e1[i:i+5],e2[i:i+5])\n",
    "        a_list.append(score)\n",
    "    array = np.array(a_list)\n",
    "    movie_indexes = np.argsort(array)\n",
    "    return movie_indexes[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to classify the segments into scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(file):\n",
    "    scenes = []\n",
    "    #read the file\n",
    "    if type(file) == str:\n",
    "        try:\n",
    "            with codecs.open(file, \"r\", \"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        try:\n",
    "            with codecs.open(file.name, \"r\", \"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    #split the screenplay into scenes\n",
    "    words = text.split()\n",
    "    length = len(words)\n",
    "    segment_length = length//100\n",
    "    for i in range(0,100):\n",
    "        segment = words[segment_length*i:segment_length*(i+1)]\n",
    "        scene = ' '.join(segment)\n",
    "        scenes.append(scene)\n",
    "    # classify the segments\n",
    "    inputs = tokenizer(scenes, padding=True, truncation=True, return_tensors=\"pt\")['input_ids']\n",
    "    outputs = np.array(model(inputs).logits.argmax(-1)).tolist()\n",
    "    labels = []\n",
    "    for i in outputs:\n",
    "        labels.append(emotion_mapping[classifier_labels[i]])\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment in Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_measures = [\"Cosine Similarity\", \"Euclidean Distance\", \"Jaro Metric\", \"Hamming Metric\", \"Levenshtein distance\"]\n",
    "def output(idx,measure):\n",
    "    if measure == 0:\n",
    "        a_list = cosine(idx)\n",
    "    if measure == 1:\n",
    "        a_list = euclid(idx)\n",
    "    if measure == 2:\n",
    "        a_list = jaro_metric(idx)\n",
    "    if measure == 3:\n",
    "        a_list = hamming(idx)\n",
    "    if measure == 4:\n",
    "        a_list = Leven(idx)\n",
    "\n",
    "    movie_names = []\n",
    "    selected_movie = df['title'][idx]\n",
    "    barcode = emo_barcode(idx)\n",
    "    b1 = emo_barcode(a_list[0])\n",
    "    b2 = emo_barcode(a_list[1])\n",
    "    b3 = emo_barcode(a_list[2])\n",
    "    b4 = emo_barcode(a_list[3])\n",
    "    b5 = emo_barcode(a_list[4])\n",
    "    for i in a_list:\n",
    "        movie_names.append(df['title'][i])\n",
    "    n1 = movie_names[0]\n",
    "    n2 = movie_names[1]\n",
    "    n3 = movie_names[2]\n",
    "    n4 = movie_names[3]\n",
    "    n5 = movie_names[4]\n",
    "    return selected_movie,barcode,n1,b1,n2,b2,n3,b3,n4,b4,n5,b5\n",
    "\n",
    "def output2(file,measure):\n",
    "    labels = classify(file)\n",
    "    barcode2 = emo_barcode_file(labels)\n",
    "    if measure == 0:\n",
    "        a_list = cosine(labels)\n",
    "    if measure == 1:\n",
    "        a_list = euclid(labels)\n",
    "    if measure == 2:\n",
    "        a_list = jaro_metric(labels)\n",
    "    if measure == 3:\n",
    "        a_list = hamming(labels)\n",
    "    if measure == 4:\n",
    "        a_list = Leven(labels)\n",
    "\n",
    "    movie_names = []\n",
    "    y1 = emo_barcode(a_list[0])\n",
    "    y2 = emo_barcode(a_list[1])\n",
    "    y3 = emo_barcode(a_list[2])\n",
    "    y4 = emo_barcode(a_list[3])\n",
    "    y5 = emo_barcode(a_list[4])\n",
    "    for i in a_list:\n",
    "        movie_names.append(df['title'][i])\n",
    "    x1 = movie_names[0]\n",
    "    x2 = movie_names[1]\n",
    "    x3 = movie_names[2]\n",
    "    x4 = movie_names[3]\n",
    "    x5 = movie_names[4]\n",
    "    return barcode2,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5\n",
    "\n",
    "    \n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Analyse Existing Screenplays\"):\n",
    "        movie_name = gr.Dropdown(choices=df['title'].to_list(),type='index', label='Choose your movie')\n",
    "        measure = gr.Dropdown(choices=similarity_measures,type='index', label=\"Select a similarity measure\")\n",
    "        button = gr.Button('Submit')\n",
    "        selected_movie = gr.Textbox()\n",
    "        barcode = gr.Image(label='Emotion Sequence')\n",
    "        n1 = gr.Textbox()\n",
    "        b1 = gr.Image(label='Emotion Sequence')\n",
    "        n2 = gr.Textbox()\n",
    "        b2 = gr.Image(label='Emotion Sequence')\n",
    "        n3 = gr.Textbox()\n",
    "        b3 = gr.Image(label='Emotion Sequence')\n",
    "        n4 = gr.Textbox()\n",
    "        b4 = gr.Image(label='Emotion Sequence')\n",
    "        n5 = gr.Textbox()\n",
    "        b5 = gr.Image(label='Emotion Sequence')\n",
    "    with gr.Tab(\"Analyse new Screenplay\"):\n",
    "        file = gr.File(label=\"Submit you file\", file_types=[\"text\"], type=\"file\")\n",
    "        measure2 = gr.Dropdown(choices=similarity_measures,type='index', label=\"Select a similarity measure\")\n",
    "        file_button = gr.Button(\"Submit file\")\n",
    "        barcode2 = gr.Image(label='Emotion Sequence')\n",
    "        x1 = gr.Textbox()\n",
    "        y1 = gr.Image(label='Emotion Sequence')\n",
    "        x2 = gr.Textbox()\n",
    "        y2 = gr.Image(label='Emotion Sequence')\n",
    "        x3 = gr.Textbox()\n",
    "        y3 = gr.Image(label='Emotion Sequence')\n",
    "        x4 = gr.Textbox()\n",
    "        y4 = gr.Image(label='Emotion Sequence')\n",
    "        x5 = gr.Textbox()\n",
    "        y5 = gr.Image(label='Emotion Sequence')\n",
    "\n",
    "    button.click(fn=output,inputs=[movie_name,measure],outputs=[selected_movie,barcode,n1,b1,n2,b2,n3,b3,n4,b4,n5,b5])\n",
    "    file_button.click(fn=output2,inputs=[file,measure2],outputs=[barcode2,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90692b742c5e732dedf6e962b701736ab0816c4096d56776820239358ac61df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
